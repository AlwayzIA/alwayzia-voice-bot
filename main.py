"""
Neo Voice Agent - AlwayzIA
API Flask pour agent vocal IA avec transcription Deepgram, GPT-4 et synth√®se ElevenLabs
"""

import os
import base64
import logging
import tempfile
import subprocess
from typing import Optional, Tuple, Dict, Any

import openai
import requests
from flask import Flask, request, jsonify, Response
from dotenv import load_dotenv

# ==================== Configuration ====================
load_dotenv()

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Variables d'environnement
class Config:
    """Configuration centralis√©e de l'application"""
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
    ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")
    DEEPGRAM_API_KEY = os.getenv("DEEPGRAM_API_KEY")
    ELEVENLABS_VOICE_ID = "kENkNtk0xyzG09WW40xE"
    GPT_MODEL = "gpt-4o-mini"
    PORT = int(os.environ.get("PORT", 5000))
    
    # Param√®tres de synth√®se vocale
    TTS_STABILITY = 0.4
    TTS_SIMILARITY_BOOST = 0.8
    
    # Param√®tres audio
    AUDIO_SAMPLE_RATE = 8000
    AUDIO_CHANNELS = 1

# Validation des cl√©s API
def validate_config() -> None:
    """Valide que toutes les cl√©s API n√©cessaires sont pr√©sentes"""
    required_keys = {
        "OPENAI_API_KEY": Config.OPENAI_API_KEY,
        "ELEVENLABS_API_KEY": Config.ELEVENLABS_API_KEY,
        "DEEPGRAM_API_KEY": Config.DEEPGRAM_API_KEY
    }
    
    missing_keys = [key for key, value in required_keys.items() if not value]
    
    if missing_keys:
        error_msg = f"Cl√©s API manquantes: {', '.join(missing_keys)}"
        logger.error(error_msg)
        raise ValueError(error_msg)

# ==================== Application Flask ====================
app = Flask(__name__)

# Configuration OpenAI
openai.api_key = Config.OPENAI_API_KEY

# ==================== Services ====================

class AudioConverter:
    """Service de conversion audio"""
    
    @staticmethod
    def mp3_to_wav(mp3_path: str, wav_path: str) -> bool:
        """
        Convertit un fichier MP3 en WAV format Twilio
        
        Args:
            mp3_path: Chemin du fichier MP3 source
            wav_path: Chemin de destination du fichier WAV
            
        Returns:
            bool: True si la conversion r√©ussit, False sinon
        """
        try:
            cmd = [
                'ffmpeg', '-i', mp3_path,
                '-ar', str(Config.AUDIO_SAMPLE_RATE),
                '-ac', str(Config.AUDIO_CHANNELS),
                '-acodec', 'pcm_mulaw',
                '-f', 'wav',
                wav_path, '-y'
            ]
            
            result = subprocess.run(
                cmd,
                check=True,
                capture_output=True,
                text=True
            )
            
            logger.info("‚úÖ Conversion audio r√©ussie")
            return True
            
        except subprocess.CalledProcessError as e:
            logger.error(f"‚ùå Erreur ffmpeg: {e.stderr}")
            return False
        except FileNotFoundError:
            logger.error("‚ùå ffmpeg non trouv√© sur le syst√®me")
            return False


class TranscriptionService:
    """Service de transcription audio avec Deepgram"""
    
    @staticmethod
    def transcribe(audio_path: str) -> Optional[str]:
        """
        Transcrit un fichier audio en texte
        
        Args:
            audio_path: Chemin du fichier audio
            
        Returns:
            str: Transcription du texte ou None si erreur
        """
        try:
            with open(audio_path, "rb") as audio_file:
                response = requests.post(
                    "https://api.deepgram.com/v1/listen",
                    headers={
                        "Authorization": f"Token {Config.DEEPGRAM_API_KEY}",
                        "Content-Type": "audio/wav"
                    },
                    files={"file": audio_file},
                    data={
                        "model": "nova",
                        "language": "fr",
                        "punctuate": True
                    }
                )
            
            if response.status_code != 200:
                logger.error(f"‚ùå Erreur Deepgram ({response.status_code}): {response.text}")
                return None
            
            result = response.json()
            transcription = result["results"]["channels"][0]["alternatives"][0]["transcript"]
            logger.info(f"üìù Transcription: {transcription}")
            return transcription
            
        except Exception as e:
            logger.error(f"‚ùå Erreur transcription: {str(e)}")
            return None


class ChatService:
    """Service de g√©n√©ration de r√©ponse avec OpenAI"""
    
    SYSTEM_PROMPT = """Tu es Neo, l'assistant vocal IA d'AlwayzIA.
    Tu es professionnel, concis et serviable.
    Tes r√©ponses sont claires et adapt√©es au contexte t√©l√©phonique.
    Limite tes r√©ponses √† 2-3 phrases maximum."""
    
    @staticmethod
    def generate_response(user_message: str) -> Optional[str]:
        """
        G√©n√®re une r√©ponse bas√©e sur le message utilisateur
        
        Args:
            user_message: Message de l'utilisateur
            
        Returns:
            str: R√©ponse g√©n√©r√©e ou None si erreur
        """
        try:
            client = openai.OpenAI(api_key=Config.OPENAI_API_KEY)
            
            response = client.chat.completions.create(
                model=Config.GPT_MODEL,
                messages=[
                    {"role": "system", "content": ChatService.SYSTEM_PROMPT},
                    {"role": "user", "content": user_message}
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            reply = response.choices[0].message.content
            logger.info(f"ü§ñ R√©ponse: {reply}")
            return reply
            
        except Exception as e:
            logger.error(f"‚ùå Erreur OpenAI: {str(e)}")
            return None


class TextToSpeechService:
    """Service de synth√®se vocale avec ElevenLabs"""
    
    @staticmethod
    def synthesize(text: str) -> Optional[bytes]:
        """
        Convertit du texte en audio
        
        Args:
            text: Texte √† convertir
            
        Returns:
            bytes: Contenu audio MP3 ou None si erreur
        """
        try:
            response = requests.post(
                f"https://api.elevenlabs.io/v1/text-to-speech/{Config.ELEVENLABS_VOICE_ID}",
                headers={
                    "xi-api-key": Config.ELEVENLABS_API_KEY,
                    "Content-Type": "application/json"
                },
                json={
                    "text": text,
                    "model_id": "eleven_multilingual_v2",
                    "voice_settings": {
                        "stability": Config.TTS_STABILITY,
                        "similarity_boost": Config.TTS_SIMILARITY_BOOST
                    }
                }
            )
            
            if response.status_code != 200:
                logger.error(f"‚ùå Erreur ElevenLabs ({response.status_code}): {response.text}")
                return None
            
            logger.info("üéµ Synth√®se vocale r√©ussie")
            return response.content
            
        except Exception as e:
            logger.error(f"‚ùå Erreur synth√®se vocale: {str(e)}")
            return None


class AudioPipeline:
    """Pipeline de traitement audio complet"""
    
    @staticmethod
    def process_request(audio_url: str) -> Tuple[Optional[str], Optional[str]]:
        """
        Traite une requ√™te audio compl√®te
        
        Args:
            audio_url: URL de l'audio √† traiter
            
        Returns:
            Tuple[str, str]: (audio_base64, message_erreur)
        """
        temp_files = []
        
        try:
            # 1. T√©l√©chargement de l'audio
            logger.info(f"üîä T√©l√©chargement: {audio_url}")
            audio_response = requests.get(audio_url)
            
            if audio_response.status_code != 200:
                return None, "Impossible de t√©l√©charger l'audio"
            
            # 2. Sauvegarde temporaire
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_wav:
                temp_wav.write(audio_response.content)
                wav_path = temp_wav.name
                temp_files.append(wav_path)
            
            # 3. Transcription
            transcription = TranscriptionService.transcribe(wav_path)
            if not transcription:
                return None, "Erreur lors de la transcription"
            
            # 4. G√©n√©ration de la r√©ponse
            response_text = ChatService.generate_response(transcription)
            if not response_text:
                return None, "Erreur lors de la g√©n√©ration de la r√©ponse"
            
            # 5. Synth√®se vocale
            audio_mp3 = TextToSpeechService.synthesize(response_text)
            if not audio_mp3:
                return None, "Erreur lors de la synth√®se vocale"
            
            # 6. Sauvegarde MP3 temporaire
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as temp_mp3:
                temp_mp3.write(audio_mp3)
                mp3_path = temp_mp3.name
                temp_files.append(mp3_path)
            
            # 7. Conversion en WAV
            final_wav_path = mp3_path.replace(".mp3", "_final.wav")
            temp_files.append(final_wav_path)
            
            if not AudioConverter.mp3_to_wav(mp3_path, final_wav_path):
                return None, "Erreur lors de la conversion audio"
            
            # 8. Encodage base64
            with open(final_wav_path, "rb") as f:
                audio_base64 = base64.b64encode(f.read()).decode("utf-8")
            
            return audio_base64, None
            
        except Exception as e:
            logger.exception("‚ö†Ô∏è Erreur dans le pipeline audio")
            return None, str(e)
            
        finally:
            # Nettoyage des fichiers temporaires
            for file_path in temp_files:
                try:
                    if os.path.exists(file_path):
                        os.unlink(file_path)
                except Exception as e:
                    logger.warning(f"Impossible de supprimer {file_path}: {e}")


# ==================== Routes ====================

@app.route('/neo', methods=['POST'])
def neo_voice_agent() -> Response:
    """
    Endpoint principal pour le traitement des appels vocaux
    
    Returns:
        Response: R√©ponse JSON avec l'audio en base64 ou erreur
    """
    try:
        logger.info("üìû Nouvelle requ√™te re√ßue sur /neo")
        
        # R√©cup√©ration de l'URL audio depuis Twilio
        recording_url = request.form.get('RecordingUrl')
        if not recording_url:
            return jsonify({'error': 'URL d\'enregistrement manquante'}), 400
        
        audio_url = f"{recording_url}.wav"
        
        # Traitement de la requ√™te
        audio_base64, error = AudioPipeline.process_request(audio_url)
        
        if error:
            logger.error(f"‚ùå Erreur: {error}")
            return jsonify({'error': error}), 500
        
        logger.info("‚úÖ Requ√™te trait√©e avec succ√®s")
        return jsonify({
            'success': True,
            'audio_base64': audio_base64
        })
        
    except Exception as e:
        logger.exception("‚ö†Ô∏è Exception non g√©r√©e")
        return jsonify({'error': 'Erreur serveur interne'}), 500


@app.route('/', methods=['GET'])
def health_check() -> str:
    """
    Endpoint de v√©rification de sant√©
    
    Returns:
        str: Message de statut
    """
    return "üöÄ Neo Voice Agent est op√©rationnel - AlwayzIA"


@app.route('/status', methods=['GET'])
def status() -> Response:
    """
    Endpoint de statut d√©taill√©
    
    Returns:
        Response: JSON avec les informations de statut
    """
    status_info = {
        'service': 'Neo Voice Agent',
        'version': '1.0.0',
        'status': 'operational',
        'configs': {
            'openai_configured': bool(Config.OPENAI_API_KEY),
            'elevenlabs_configured': bool(Config.ELEVENLABS_API_KEY),
            'deepgram_configured': bool(Config.DEEPGRAM_API_KEY)
        }
    }
    return jsonify(status_info)


# ==================== Point d'entr√©e ====================

if __name__ == "__main__":
    try:
        # Validation de la configuration
        validate_config()
        
        logger.info("=" * 50)
        logger.info("üöÄ D√©marrage de Neo Voice Agent")
        logger.info(f"üì° Port: {Config.PORT}")
        logger.info("=" * 50)
        
        # D√©marrage du serveur
        app.run(
            host="0.0.0.0",
            port=Config.PORT,
            debug=False  # Ne jamais activer debug en production
        )
        
    except Exception as e:
        logger.error(f"‚ùå Impossible de d√©marrer l'application: {e}")
        exit(1)
